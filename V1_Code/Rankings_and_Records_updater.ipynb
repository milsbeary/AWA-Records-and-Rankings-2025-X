{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0Mc2xBGSavu"
   },
   "outputs": [],
   "source": [
    "#1)\n",
    "\n",
    "#This script updates the AWA rankings and records sheets with each competition\n",
    "\n",
    "#It is important to note that this notebook is meant to run in google colab and interact with a google drive\n",
    "#If you want to run locally, you will need to make some modifications\n",
    "\n",
    "#Last modified on September 14th, 2025 by M. H. Kent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk0wT2L-Su4Q",
    "outputId": "4f2cafef-9c52-402a-96a2-9740744731ef"
   },
   "outputs": [],
   "source": [
    "#2)\n",
    "\n",
    "#Import needed libraries to run the script\n",
    "\n",
    "#Install needed packages that are not already built in\n",
    "!pip install XlsxWriter\n",
    "!pip install rapidfuzz\n",
    "!pip install gspread_formatting\n",
    "\n",
    "#Import needed packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "import math\n",
    "from datetime import datetime\n",
    "from google.colab import drive\n",
    "from google.colab import files\n",
    "from google.colab import auth\n",
    "import openpyxl as opxl\n",
    "from openpyxl.styles import Font, Alignment, Border, Side\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.cell.cell import MergedCell\n",
    "import xlsxwriter\n",
    "from rapidfuzz.distance import Levenshtein\n",
    "from rapidfuzz import process, fuzz\n",
    "from datetime import datetime\n",
    "import time\n",
    "import gspread\n",
    "from gspread_dataframe import get_as_dataframe\n",
    "from google.colab import auth\n",
    "import google.auth\n",
    "from gspread_dataframe import get_as_dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtaMSU6oS9Jh",
    "outputId": "b750b402-fd5c-4df4-c856-272a9f9eb95d"
   },
   "outputs": [],
   "source": [
    "#3)\n",
    "\n",
    "#Conect to the drive\n",
    "#Run through the prompts that pop up. Accept what they ask and you will have full conection\n",
    "\n",
    "#Authenticate to the user\n",
    "#auth.authenticate_user() #Unhash if you have never mounted before or you have issues\n",
    "\n",
    "#Mount to the drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOJx16-hTaGn"
   },
   "outputs": [],
   "source": [
    "#4)\n",
    "\n",
    "#Setting all of the nessisary paths and specifications to run the updates\n",
    "\n",
    "#Determine what to update online\n",
    "#Set as \"True\" if we want to update on a website or the core docs in a google drive, \"False\" otherwise\n",
    "onl_upd_recs = False #Reccord sheet\n",
    "onl_upd_rank = False #Ranking sheet\n",
    "\n",
    "#Set paths to each sheet we need to preform updates on or upload from\n",
    "#Note that the input and output path will be the same for the updates sheets\n",
    "#Make sure that the file types are correct, excell vs sheets is finiky\n",
    "#Note that you will need to change these paths to your own\n",
    "#GO TO CELL 6 WHEN YOU KNOW IF YOU ARE USEING .XLSX FILES OR GOOGLE SHEETS\n",
    "\n",
    "#Update sheet\n",
    "res_to_add_path = \"/content/drive/your sheet path here\"\n",
    "\n",
    "#Records sheet\n",
    "rec_sheet_path = \"/content/drive/your sheet path here\"\n",
    "\n",
    "#Rankings sheet\n",
    "#rank_sheet_path = \"Your path here\"\n",
    "rank_sheet_ID = \"your google sheet id here\" #This is because a google sheet was used here in the original awa code\n",
    "\n",
    "#Classification sheet\n",
    "class_sheet_path = \"/content/drive/your sheet path here\"\n",
    "\n",
    "#Sinclair coefficent sheet\n",
    "sinc_sheet_path = \"/content/drive/you sheet path here\"\n",
    "\n",
    "#Q-Points masters age factors sheets\n",
    "Q_agef_sheet = \"/content/drive/your sheet path here\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SMvD6wyKOfH"
   },
   "outputs": [],
   "source": [
    "#5)\n",
    "\n",
    "#Define all needed functions\n",
    "\n",
    "\n",
    "#Define needed functions for Q-points and Sinclair\n",
    "\n",
    "#q_points formulas found here https://osf.io/e6srt\n",
    "def q_points_male(total, bodyweight):\n",
    "  \"\"\"\n",
    "  Computes the Q points score for men\n",
    "\n",
    "  total: The total hit in kg\n",
    "  bodyweight: The body weight\n",
    "  \"\"\"\n",
    "  bw_ratio = bodyweight / 100\n",
    "  denominator = 416.70 - 47.87 * bw_ratio**(-2) + 18.93 * bw_ratio**2\n",
    "  return (total * 463.26) / denominator\n",
    "\n",
    "def q_points_female(total, bodyweight):\n",
    "  \"\"\"\n",
    "  Computes the Q points score for woman\n",
    "\n",
    "  total: The total hit in kg\n",
    "  bodyweight: The body weight\n",
    "  \"\"\"\n",
    "  bw_ratio = bodyweight / 100\n",
    "  denominator = 266.50 - 19.44 * bw_ratio**(-2) + 18.61 * bw_ratio**2\n",
    "  return (total * 306.54) / denominator\n",
    "\n",
    "def qbw_male(bodyweight):\n",
    "  \"\"\"\n",
    "  Computes the Q point bodyweight factor for men\n",
    "\n",
    "  bodyweight: The body weight\n",
    "  \"\"\"\n",
    "  bw_ratio = bodyweight / 100\n",
    "  denominator = 416.70 - 47.87 * bw_ratio**(-2) + 18.93 * bw_ratio**2\n",
    "  return 463.26 / denominator\n",
    "\n",
    "def qbw_female(bodyweight):\n",
    "  \"\"\"\n",
    "  Computes the Q points bodyweight factor for woman\n",
    "\n",
    "  bodyweight: The body weight\n",
    "  \"\"\"\n",
    "  bw_ratio = bodyweight / 100\n",
    "  denominator = 266.50 - 19.44 * bw_ratio**(-2) + 18.61 * bw_ratio**2\n",
    "  return 306.54 / denominator\n",
    "\n",
    "def sinclair_coef(x, A, b):\n",
    "  \"\"\"\n",
    "  Defines the sinclair coefficent formula\n",
    "\n",
    "  x: The athletes bodyweight\n",
    "  A: The sinclair coefficent A value\n",
    "  b: The sinclair coefficent b value\n",
    "  \"\"\"\n",
    "  div_const = float(float(x)/float(b))\n",
    "  big_X = math.log10(div_const)\n",
    "  if x <= b:\n",
    "      return 10**(A*(big_X**2))\n",
    "  if x > b:\n",
    "      return 1\n",
    "\n",
    "def sinclair_masters_mod(Ag, Age):\n",
    "  \"\"\"\n",
    "  Defines the sinclair age coefficent modeification for masters athletes\n",
    "\n",
    "  Age: The athletes age\n",
    "  Ag: The sinclair age coefficent\n",
    "  \"\"\"\n",
    "  return 1 + ((Ag/100)*(Age - 30))\n",
    "\n",
    "def sinclair_total(total, x, A, b):\n",
    "  \"\"\"\n",
    "  Calculates the sinclair total from the coefficent\n",
    "\n",
    "  total: The athletes total hit\n",
    "  x: The athletes bodyweight\n",
    "  A: The sinclair coefficent A value\n",
    "  b: The sinclair coefficent b value\n",
    "  \"\"\"\n",
    "  return total * sinclair_coef(x, A, b)\n",
    "\n",
    "def masters_sinclair_total(total, x, A, b, Ag, Age):\n",
    "  \"\"\"\n",
    "  Calculates the sinclair total from the coefficent\n",
    "\n",
    "  total: The athletes total hit\n",
    "  x: The athletes bodyweight\n",
    "  A: The sinclair coefficent A value\n",
    "  b: The sinclair coefficent b value\n",
    "  \"\"\"\n",
    "  return total * sinclair_coef(x, A, b) * sinclair_masters_mod(Ag, Age)\n",
    "\n",
    "def list_rounder(num_list):\n",
    "  \"\"\"\n",
    "  Rounds each float in a list to the nearest whole integer\n",
    "\n",
    "  num_list: A list of floats\n",
    "  \"\"\"\n",
    "  return [round(num) for num in num_list]\n",
    "\n",
    "\n",
    "#Define needed functions for file uploads and basic cleaning\n",
    "\n",
    "def sheet_dict_creater(pathID, subsheets, type, auth):\n",
    "  \"\"\"\n",
    "  Uploads the specified subsheets from a path or an ID depending on the file type\n",
    "  This function is currently equipt to handle .xlsx and .gsheet files\n",
    "\n",
    "  pathID: The file id of the .gsheet files or the full path of the .xlxs file\n",
    "  subsheet: A list of subsheet names as a string\n",
    "  type: Spefifies if we are working with a .gsheet or .xlsx file. The possible inputs are \"gsheet\" and \"xlsx\"\n",
    "  auth: Specifies if we need to remount to the drive or authenticate the user for the google sheet upload. \"True\" Means that we do\n",
    "  \"\"\"\n",
    "  if type == \"gsheet\":\n",
    "    if auth == True:\n",
    "      from google.colab import auth\n",
    "      import google.auth\n",
    "      auth.authenticate_user()\n",
    "      creds, _ = google.auth.default()\n",
    "      gc = gspread.authorize(creds)\n",
    "    file_dict = {}\n",
    "    for sheet in subsheets:\n",
    "      sheet_file = gc.open_by_key(pathID).worksheet(sheet)\n",
    "      file_dict[sheet] = get_as_dataframe(sheet_file, evaluate_formulas=True)\n",
    "    return file_dict\n",
    "  elif type == \"xlsx\":\n",
    "    if auth == True:\n",
    "      drive.mount('/content/drive')\n",
    "    file_dict = {}\n",
    "    for sheet in subsheets:\n",
    "      #print(sheet)\n",
    "      file_dict[sheet] = pd.read_excel(pathID, sheet_name = sheet)\n",
    "    return file_dict\n",
    "\n",
    "def rank_sheet_mod1(rank_dict):\n",
    "  \"\"\"\n",
    "  Fixes the ranking sheet so we preform the nessisary updates\n",
    "\n",
    "  rank_dict: The raw ranking sheet dictionary\n",
    "  \"\"\"\n",
    "  clean_sheet_dict = {}\n",
    "  for keys in list(rank_dict.keys()):\n",
    "    sheet = rank_dict[keys]\n",
    "    sheet = sheet.reset_index(drop = True)\n",
    "    sheet.columns = sheet.iloc[0]\n",
    "    sheet = sheet[1:]\n",
    "    clean_sheet_dict[keys] = sheet\n",
    "  return clean_sheet_dict\n",
    "\n",
    "def rec_sheet_mod1(rec_dict):\n",
    "  \"\"\"\n",
    "  Fixes the ranking sheet so we preform the nessisary updates\n",
    "\n",
    "  rec_dict: The raw ranking sheet dictionary\n",
    "  \"\"\"\n",
    "  clean_sheet_dict = {}\n",
    "  for keys in list(rec_dict.keys()):\n",
    "    sheet = rec_dict[keys]\n",
    "    sheet = sheet.reset_index(drop = True)\n",
    "    sheet.columns = sheet.iloc[0]\n",
    "    sheet = sheet[1:]\n",
    "    clean_sheet_dict[keys] = sheet\n",
    "  return clean_sheet_dict\n",
    "\n",
    "def upd_sheet_colbuild(cnames, rwone):\n",
    "  \"\"\"\n",
    "  Builds the columns of the update sheet from the first row and the original column names\n",
    "  The goal is for us to be able to identify the columns that we need for our updates from this\n",
    "  We assume that both the first row and the cnames list are the same\n",
    "\n",
    "  cnames: The initial colnames of the sheet\n",
    "  rwone: The first row of the update dataframe\n",
    "  \"\"\"\n",
    "  new_cnames = []\n",
    "  for i in range(len(cnames)):\n",
    "    cname = cnames[i]\n",
    "    rval = rwone[i]\n",
    "    if 'Unnamed:' in cname:\n",
    "      new_cnames.append(str(rval)) #Make sure it is a string\n",
    "    else:\n",
    "      new_cnames.append(cname)\n",
    "  return new_cnames\n",
    "\n",
    "def sn_cj_colname_mod(colnmlst):\n",
    "  \"\"\"\n",
    "  Modifies any list of column names that has only integer values for snatch and clean and jerk column names if they exist\n",
    "\n",
    "  colnmlst: The list of column names that we want to preform the mod for\n",
    "  \"\"\"\n",
    "  new_cnames = []\n",
    "  ider = 0\n",
    "  for i in range(len(colnmlst)):\n",
    "    cname = str(colnmlst[i])\n",
    "    if 'Snatch' in cname:\n",
    "      new_cnames.append('Snatch_1')\n",
    "      ider = 1\n",
    "    elif 'Clean&Jerk' in cname:\n",
    "      new_cnames.append('Clean&Jerk_1')\n",
    "      ider = 2\n",
    "    elif ider == 1 and cname in ['2', '3', 'max']:\n",
    "      new_name = 'Snatch_' + cname\n",
    "      new_cnames.append(new_name)\n",
    "    elif ider == 2 and cname in ['2', '3', 'max']:\n",
    "      new_name = 'Clean&Jerk_' + cname\n",
    "      new_cnames.append(new_name)\n",
    "    else:\n",
    "      new_cnames.append(cname)\n",
    "      ider = 0\n",
    "  return new_cnames\n",
    "\n",
    "def upd_sheet_mod1(upd_sheet):\n",
    "  \"\"\"\n",
    "  Modifies the update sheet so we can do the updates to the rankings and records\n",
    "\n",
    "  upd_sheet: The update sheet as a pandas dataframe\n",
    "  \"\"\"\n",
    "  sheet = upd_sheet.reset_index(drop = True)\n",
    "  columns = list(sheet.columns)\n",
    "  row_1 = list(sheet.iloc[0])\n",
    "  cnames_1 = upd_sheet_colbuild(columns, row_1)\n",
    "  cnames_2 = sn_cj_colname_mod(cnames_1)\n",
    "  sheet.columns = cnames_2\n",
    "  sheet = sheet[1:]\n",
    "  return sheet\n",
    "\n",
    "def classification_setup(file_path, sheet_nm):\n",
    "  \"\"\"\n",
    "  Uploads the classification sheet and gets it into the correct format to update\n",
    "\n",
    "  file_path: The path to the classification sheet\n",
    "  sheet_nm: The sheet name of the classification sheet within the larger file\n",
    "  \"\"\"\n",
    "  mens_class_base = pd.read_excel(file_path, sheet_name=sheet_nm ,skiprows=3, nrows=9, usecols=lambda column: column != 'Unnamed: 0')\n",
    "  mens_class = ((mens_class_base.drop(index=0)).reset_index(drop=True)).round(0)\n",
    "  mens_class['Novice'] = list_rounder(list(mens_class.loc[:,'Novice'])) #Rounds the one row that did not automatically round for some reason\n",
    "  mens_class['Category'] = mens_class['Category'].str.replace('kg', '', regex=False)\n",
    "  womans_class_base = pd.read_excel(file_path, sheet_name=sheet_nm, skiprows=14, nrows=9, usecols=lambda column: column != 'Unnamed: 0')\n",
    "  womans_class = ((womans_class_base.drop(index=0)).reset_index(drop=True)).round(0)\n",
    "  womans_class['Novice'] = list_rounder(list(womans_class.loc[:,'Novice'])) #Rounds the one row that did not automatically round for some reason\n",
    "  womans_class['Category'] = womans_class['Category'].str.replace('kg', '', regex=False)\n",
    "  return mens_class, womans_class\n",
    "\n",
    "def collsplit(df):\n",
    "  \"\"\"\n",
    "  Splits a single column dataframe into a dataframe with multiple columns by space\n",
    "\n",
    "  df: The dataframe we want to preform this action to\n",
    "  \"\"\"\n",
    "  new_colnames = df.columns.str.split(expand=True)[0] #The zero is because it is a tuple\n",
    "  split_df = df[df.columns[0]].str.split(expand=True)\n",
    "  split_df.columns = new_colnames\n",
    "  return split_df\n",
    "\n",
    "def two_combine(df, col1, col2, newcolname):\n",
    "  \"\"\"\n",
    "  Combines the two columns where both column enteries are seperated by a space in a new columns\n",
    "\n",
    "  df: The dataframe\n",
    "  col1: The column name of the leading column\n",
    "  col2: The column name of the trailing column\n",
    "  newcolname: The name of the new column\n",
    "  \"\"\"\n",
    "  df[newcolname] = df[col1] + \" \" + df[col2]\n",
    "  df.drop(columns=[col1, col2], inplace=True)\n",
    "  return df\n",
    "\n",
    "def upd_sheed_upload(sheet_path):\n",
    "  \"\"\"\n",
    "  Uploads all of the tabs on the update sheet and makes the needed modifications\n",
    "\n",
    "  sheet_path: The path to the update sheet\n",
    "  \"\"\"\n",
    "  upd_sheet = pd.ExcelFile(sheet_path, engine='openpyxl')\n",
    "  sheets = list(upd_sheet.sheet_names)\n",
    "  sheet_dict = {}\n",
    "  non_matched = {}\n",
    "  for sheet in sheets:\n",
    "    print(sheet)\n",
    "    sheet_in = pd.read_excel(upd_sheet, sheet_name=sheet)\n",
    "    #print(sheet_in.columns)\n",
    "    if sheet_in.shape[1] == 1: #We assume it is a pdf form\n",
    "      if list(sheet_in.columns)[0] == \"Lot Last_Name First_Name Group Sex W.C. B.W. Team Born Snatch_1 Snatch_2 Snatch_3 Snatch_max Clean&Jerk_1 Clean&Jerk_2 Clean&Jerk_3 Clean&Jerk_max Total Sinclair Rank\":\n",
    "        df_update = collsplit(sheet_in)\n",
    "        df_update = two_combine(df_update, \"Sex\", \"W.C.\", \"Cat\")\n",
    "        #df_update.drop(columns=[\"Group\"], inplace=True)\n",
    "        sheet_dict[sheet] = df_update\n",
    "      elif list(sheet_in.columns)[0] == \"Lot Last_Name First_Name Cat. W.C. B.W. Team Born Snatch_1 Snatch_2 Snatch_3 Snatch_max R1 Clean&Jerk_1 Clean&Jerk_2 Clean&Jerk_3 Clean&Jerk_max R2 Total Rank\":\n",
    "        df_update = collsplit(sheet_in)\n",
    "        df_update = two_combine(df_update, \"Cat.\", \"W.C.\", \"Cat\")\n",
    "        sheet_dict[sheet] = df_update\n",
    "      else:\n",
    "        print(\"Warning: \", sheet, \" Does not match any known format for single column initial\")\n",
    "        non_matched[sheet] = sheet_in\n",
    "    elif sheet_in.shape[1] in [16, 18]: #Assuming possible OWLCSM forms\n",
    "      upd_to_upd = upd_sheet_mod1(sheet_in)\n",
    "      sheet_dict[sheet] = upd_to_upd\n",
    "    elif sheet_in.shape[1] == 17: #Assuming a non OWLCSM\n",
    "      #upd_to_upd = upd_sheet_mod1(sheet_in)\n",
    "      sheet_dict[sheet] = sheet_in\n",
    "    #elif sheet_in.shape[1] == 20: #This is one of the clean sheets we initially got\n",
    "    #  sheet_dict[sheet] = sheet_in\n",
    "    else: #We add it to a different dataframe and print a warning\n",
    "      print(\"Warning: \", sheet, \" Does not match any known format\")\n",
    "      non_matched[sheet] = sheet_in\n",
    "  return sheet_dict, non_matched\n",
    "\n",
    "def unrec_frame(non_matched_frame):\n",
    "  \"\"\"\n",
    "  Causes the code to stop if there a dataframes in which we do not reccognize the form\n",
    "\n",
    "  non_matched_frame: The dictionary of non matched dataframes ie the ones we do not recognize\n",
    "  \"\"\"\n",
    "  assert len(non_matched_frame) == 0\n",
    "\n",
    "def match_closest(value, candidates, threshold=85):\n",
    "  \"\"\"\n",
    "  Finds the closest string in a set of canidates\n",
    "\n",
    "  value: The string we want to test\n",
    "  Canidates: The list of strings we want to compare to\n",
    "  Threshold: How simmilar strings can be and still return what is needed\n",
    "  \"\"\"\n",
    "  if value in candidates:\n",
    "    return (value, 100, np.nan)\n",
    "  result = process.extractOne(value, candidates, scorer=fuzz.ratio)\n",
    "  if result and result[1] >= threshold:\n",
    "      return (value, result[1], result[0]) # matched value\n",
    "  return \"None\"  # or return value if you want to preserve original\n",
    "\n",
    "def simp_name_replacer(df):\n",
    "  \"\"\"\n",
    "  Replaces the names of the columns that are stagnent\n",
    "\n",
    "  df: The dataframe we know we want to do the replaceing for\n",
    "  \"\"\"\n",
    "  #Set the simple names that we want to replace\n",
    "  simp_repnames = [\"Last_Name\", \"First_Name\", \"Cat\", \"B.W.\", \"Club\"]\n",
    "  #Setting weight class varients so we can identify What we need to replace here\n",
    "  weightclass_variants = [\"weightclass\", \"weight class\", \"weight_class\", \"wtclass\", \"wt class\", \"wclass\", \"w class\", \"w_class\", \"wgtclass\", \"wgt class\", \"wgt_class\",\n",
    "                          \"wc\", \"weight-category\", \"weight category\", \"weight-cat\", \"weight cat\", \"wt.\", \"division\", \"class\", \"category\", \"cat.\", \"Cat\", \"Cat.\"]\n",
    "  #Setting the body weight varients\n",
    "  bodyweight_variants = [\"bodyweight\", \"body weight\", \"body_weight\", \"bdyweight\", \"bweight\", \"bw\", \"wt\", \"weight\", \"weigh\", \"athlete weight\", \"competition weight\", \"weigh-in\", \"weighin\",\n",
    "    \"wgt\", \"comp weight\", \"weightkg\", \"kg\", \"mass\", \"B.W.\", \"b.w.\"]\n",
    "  #Setting the first name and last name varients\n",
    "  first_name_varients = [\"first name\", \"firstname\", \"first_name\", \"fname\", \"f name\", \"given name\", \"given_name\", \"first\", \"forename\", \"First_Name\", \"First Name\", \"First_name\"]\n",
    "  last_name_varients = [\"last name\", \"lastname\", \"last_name\", \"lname\", \"l name\", \"surname\", \"family name\", \"family_name\", \"last\", \"Last_Name\", \"Last Name\", \"Last_name\"]\n",
    "  #Setting all of the team name varients\n",
    "  team_varients = [\"team\", \"Team\", \"teamname\", \"team_name\", \"Team_name\", \"Team\", \"Name\" \"Club\", \"club\", \"Team\"]\n",
    "  \"Building the dictionary of names\"\n",
    "  var_list = [last_name_varients, first_name_varients, weightclass_variants, bodyweight_variants, team_varients]\n",
    "  var_dict = {}\n",
    "  for i in range(len(simp_repnames)):\n",
    "    var_dict[simp_repnames[i]] = var_list[i]\n",
    "  #Itterate over each of the column names and replace as we see if\n",
    "  df_names = list(df.columns)\n",
    "  for simp_name in simp_repnames:\n",
    "    high_var = 0\n",
    "    replace_name = \"\"\n",
    "    canidates = var_dict[simp_name]\n",
    "    for cname in df.columns:\n",
    "      clost_tup = match_closest(cname, canidates, threshold=85)\n",
    "      if clost_tup != \"None\":\n",
    "        df_cname, per_clo, cl_in_list = clost_tup\n",
    "        if per_clo > high_var:\n",
    "          high_var = per_clo\n",
    "          replace_name = df_cname\n",
    "    if replace_name != \"\":\n",
    "      df = df.rename(columns={replace_name: simp_name})\n",
    "  return df\n",
    "\n",
    "def column_samer(raw_upd_dict):\n",
    "  \"\"\"\n",
    "  Makes sure that all of the column names of each dataframe in the dictionary is the same\n",
    "\n",
    "  raw_upd_dict: The dictionary of dataframes we want to comvert the colnames to\n",
    "  cols_we_want: The column names that we want both dataframes to have. For now we assume it is the input from the OWLMS system\n",
    "  \"\"\"\n",
    "  #Set the columns we want to replace\n",
    "  unif_cols = [\"Lot\", \"Last_Name\", \"First_Name\", \"M/F\", \"Cat\", \"B.W.\", \"Team\", \"Born\", \"Snatch_1\", \"Snatch_2\", \"Snatch_3\", \"Snatch_max\",\n",
    "               \"Clean&Jerk_1\", \"Clean&Jerk_2\", \"Clean&Jerk_3\", \"Clean&Jerk_max\", \"Total\", \"Sinclair\", \"Cat. Rank\", \"Q-masters\"]\n",
    "  #Do the replaceing that we want\n",
    "  dfs_to_add = list(raw_upd_dict.keys())\n",
    "  new_clean_dict = {}\n",
    "  for key in dfs_to_add:\n",
    "    df = raw_upd_dict[key]\n",
    "    df_cols = list(df.columns)\n",
    "    if df_cols != unif_cols:\n",
    "        df = simp_name_replacer(df) #Start with some brunt force replacement\n",
    "        if \"Q-masters\" not in df.columns: #Adding what we use for rank if it is not in the frame that we need\n",
    "          df[\"Q-masters\"] = np.nan\n",
    "        if \"Sinclair\" not in df.columns:\n",
    "          df[\"Sinclair\" ] = np.nan\n",
    "        new_clean_dict[key] = df\n",
    "    else: #If it is the same we are good\n",
    "      new_clean_dict[key] = df\n",
    "  return new_clean_dict\n",
    "\n",
    "\n",
    "#Functions for adding needed information to the update dictionary\n",
    "\n",
    "def comp_age_adder(upd_sheet, comp_date, bd_col, newcol_name, newcol_name_2):\n",
    "  \"\"\"\n",
    "  Adds the age that the athlete was at the competition to the sheet\n",
    "  This function also adds the year of birth of the athlete to the sheet\n",
    "\n",
    "  upd_sheet: The sheet we are updating and adding the athletes age to\n",
    "  comp_date: The date string of the competition\n",
    "  bd_col: The column that specifies the athletes birthdate\n",
    "  newcol_name: The name of the column we want to add to the sheet for the athletes age\n",
    "  newcol_name_2: The name of the column we want to add to the sheet for the athletes year of birth\n",
    "  \"\"\"\n",
    "  comp_dt = datetime.strptime(comp_date, \"%Y-%m-%d\")\n",
    "  comp_year = int(comp_dt.year)\n",
    "  ages = []\n",
    "  yob = []\n",
    "  upd_rownum = upd_sheet.shape[0]\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  for i in range(upd_rownum):\n",
    "    birth_date = upd_sheet.loc[i, bd_col]\n",
    "    #print(birth_date)\n",
    "    try: #See if we have a year only\n",
    "      birth_year = int(birth_date)\n",
    "      ages.append(comp_year - birth_year)\n",
    "      yob.append(birth_year)\n",
    "      continue\n",
    "    except: #See if we can convert to a timestamp\n",
    "      birth_date = pd.Timestamp(birth_date)\n",
    "    #if isinstance(birth_date, pd.Timestamp):\n",
    "      birth_year = birth_date.year\n",
    "      ages.append(comp_year - birth_year)\n",
    "      yob.append(birth_year)\n",
    "      continue\n",
    "  upd_sheet[newcol_name] = ages\n",
    "  upd_sheet[newcol_name_2] = yob\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  return upd_sheet\n",
    "\n",
    "def catagory_adder(upd_sheet, age_col, new_colname):\n",
    "  \"\"\"\n",
    "  Adds the athletes catagory to the sheet\n",
    "\n",
    "  upd_sheet: The sheet we are updating and adding the athletes age to\n",
    "  age_col: The column that specifies the athletes age\n",
    "  new_colname: The name of the column we want to add to the sheet\n",
    "  \"\"\"\n",
    "  catagories = []\n",
    "  upd_rownum = upd_sheet.shape[0]\n",
    "  for i in range(upd_rownum):\n",
    "    age_in_q =  float(upd_sheet.loc[i, age_col]) #Makes sure it is a number if possible\n",
    "    if age_in_q < 17:\n",
    "      catagories.append('YTH')\n",
    "    elif age_in_q < 21:\n",
    "      catagories.append('JR')\n",
    "    elif age_in_q < 30:\n",
    "      catagories.append('SR')\n",
    "    elif isinstance(age_in_q , (int, float)): #If it is a number greater then 30\n",
    "      catagories.append('MST')\n",
    "    else:\n",
    "      catagories.append(np.nan)\n",
    "  upd_sheet[new_colname] = catagories\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  return upd_sheet\n",
    "\n",
    "def WC_clean(df, wc_col, plus_back):\n",
    "  \"\"\"\n",
    "  Cleans up the weightclass column to be in the form we need\n",
    "  This applied to the HW weight catagories where the + and > can be all over the place\n",
    "  df: The dataframe we want to preform this action to\n",
    "  wc_col: The column name of the weightclass column\n",
    "  plus_back: Specifies if we want + at the back of each weightclass in the row\n",
    "  \"\"\"\n",
    "  df[wc_col] = df[wc_col].str.replace('>', '+', regex=False) #Do the simplest change first\n",
    "  if plus_back: #Moves the plus to the back of the dataframe if true\n",
    "    df[wc_col] = df[wc_col].str.replace('+', '', regex=False) + \\\n",
    "                 df[wc_col].str.contains(r'\\+').map(lambda x: '+' if x else '')\n",
    "  return df\n",
    "\n",
    "def mst_ageadd(df, gro_col, new_col, mst_agecats, ath_agecol):\n",
    "  \"\"\"\n",
    "  Adds the masters age catagories to the sheet for the masters athletes\n",
    "\n",
    "  df: The df we want to add this information to\n",
    "  gru_col: The catagory that signifies what group the athlete is in\n",
    "  new_col: The new colname we want to use\n",
    "  mst_agecats: The list of masters age categories in numerical order. This is a string of integers separated by commas. The last element in this list should be int('inf')\n",
    "  ath_agecol: The column that specifies the athletes age\n",
    "  \"\"\"\n",
    "  df = df.reset_index(drop=True)\n",
    "  upd_rownum = df.shape[0]\n",
    "  mst_cat = []\n",
    "  for i in range(upd_rownum):\n",
    "    gro_in_q = str(df.loc[i, gro_col])\n",
    "    age_in_1 = float(df.loc[i, ath_agecol])\n",
    "    if gro_in_q == 'MST':\n",
    "        for age in range(len(mst_agecats)):\n",
    "            if age_in_1 < mst_agecats[age]:\n",
    "                mst_cat.append(mst_agecats[age-1])\n",
    "                break\n",
    "    else:\n",
    "        mst_cat.append(np.nan)\n",
    "  df[new_col] = mst_cat\n",
    "  df = df.reset_index(drop=True)\n",
    "  return df\n",
    "\n",
    "def col_seperater_space(df, col1, col2, to_split_col):\n",
    "  \"\"\"\n",
    "  Splits one column in a dataframe to two seperate columns by a space\n",
    "  Note we only split after the first occurence\n",
    "\n",
    "  df: The dataframe we want to preform this action to\n",
    "  col1: The column name of the leading column\n",
    "  col2: The column name of the trailing column\n",
    "  to_split_col: The column name we want to split\n",
    "  \"\"\"\n",
    "\n",
    "  df[[col1, col2]] = df[to_split_col].str.split(r\"\\s+\", n=1, expand=True)\n",
    "  df = df.reset_index(drop=True)\n",
    "  return df\n",
    "\n",
    "def MFW_seperator(df, col1, col2, to_split_col):\n",
    "  \"\"\"\n",
    "  Splits after M, F, or W in a column to two seperate columns\n",
    "  Note we only split after the first occurence\n",
    "\n",
    "  df: The dataframe we want to preform this action to\n",
    "  col1: The column name of the leading column\n",
    "  col2: The column name of the trailing column\n",
    "  to_split_col: The column name we want to split\n",
    "  \"\"\"\n",
    "  #df[[col1, col2]] = df[to_split_col].str.split(r\"(?<=[MFW])\\s+\", n=1, expand=True)\n",
    "  #df = df.reset_index(drop=True)\n",
    "  df = df.reset_index(drop = True) #Doing manually bc it is not working the way I want\n",
    "  colel1 = []\n",
    "  colel2 = []\n",
    "  for i in range(df.shape[0]):\n",
    "    look_el = str(df.loc[i, to_split_col][0])\n",
    "    if look_el == 'M':\n",
    "      colel1.append('M')\n",
    "      colel2.append(look_el.replace('M', ''))\n",
    "    elif look_el == 'F':\n",
    "      colel1.append('F')\n",
    "      colel2.append(look_el.replace('F', ''))\n",
    "    elif look_el == 'W':\n",
    "      colel1.append('W')\n",
    "      colel2.append(look_el.replace('W', ''))\n",
    "    #else: #This is cancled out so we see if there are any mistakes or weird cols as there will be a missmatch in column size\n",
    "    #  colel1.append(np.nan)\n",
    "    #  colel2.append(np.nan)\n",
    "  df[col1] = colel1\n",
    "  df[col2] = colel2\n",
    "  return df\n",
    "\n",
    "def clean_cat_col(df, gro_col, sex_col, wc_col, mst_age, new_colname):\n",
    "  \"\"\"\n",
    "  Adds the proper catagory column name to the dataframes\n",
    "\n",
    "  df: The dataframe we want to add the catagory to\n",
    "  gro_col: The catagory that signifies what group the athlete is in\n",
    "  sex_col: The column that specifies the athletes sex\n",
    "  wc_col: The column that specifies the athletes weight class\n",
    "  mst_age: The age catagory\n",
    "  new_colname: The name of the column we want to add to the sheet\n",
    "  \"\"\"\n",
    "  df = df.reset_index(drop=True)\n",
    "  upd_rownum = df.shape[0]\n",
    "  cats = []\n",
    "  for i in range(upd_rownum):\n",
    "    gro_in_q = str(df.loc[i, gro_col])\n",
    "    sex_in_q = str(df.loc[i, sex_col])\n",
    "    wc_in_q = str(df.loc[i, wc_col])\n",
    "    ms_in_q = df.loc[i, mst_age]\n",
    "    if gro_in_q == 'Mst':\n",
    "      str_append = str(sex_in_q + str(int(ms_in_q)) + ' ' + wc_in_q)\n",
    "      cats.append(str_append)\n",
    "    else:\n",
    "      str_append = str(sex_in_q + ' ' + wc_in_q)\n",
    "      cats.append(str_append)\n",
    "  df[new_colname] = cats\n",
    "  df = df.reset_index(drop=True)\n",
    "  return df\n",
    "\n",
    "def scale_factor_locator(scal_fact_df, age, sex):\n",
    "    \"\"\"\n",
    "    Locates the masters scale factor we want to scale by\n",
    "\n",
    "    scal_fact_df: The scale factor dataframe as defined above\n",
    "    age: The intiger age we want to get the scale factor for\n",
    "    sex: The sex of the athlete we want to get the scale factor for as M or F\n",
    "    \"\"\"\n",
    "    scal_fact_df = scal_fact_df[scal_fact_df[\"Age\"] == int(age)]\n",
    "    scal_fact_df = scal_fact_df.reset_index(drop=True)\n",
    "    if sex == \"M\":\n",
    "        return scal_fact_df.at[0, \"AgeFactor_Men\"]\n",
    "    elif sex == \"F\":\n",
    "        return scal_fact_df.at[0, \"AgeFactor_Women\"]\n",
    "    else:\n",
    "        print(\"sex needs to be M or F, here comes an error\")\n",
    "\n",
    "def sinclair_Q_adder(upd_sheet, sinclair_table, Q_agef_sheet, Q_col, Q_mst_col, WC_sinc_col, Bw_sinc_col, age_col, tot_col, sex_col, bw_col, wc_col): #masters_men_table, masters_woman_table master_mens_table: The coefficent sheet for the mens weightclasses master_womans_table: The coeffcent sheet for the womans weightclasses,\n",
    "  \"\"\"\n",
    "  Adds the sinclair and Q points columns score to the update sheet\n",
    "\n",
    "  upd_sheet: The dataframe we want to add the sinclair and Q points to for masters\n",
    "  Q_col: The column name that we want the Q points to be in\n",
    "  Q_mst_col: The column name that we want the Q points for masters to be in\n",
    "  WC_sinc_col: The column name that we want the sinclair to be in\n",
    "  Bw_sinc_col: The column name that we want the body weight to be in\n",
    "  age_col: The column name that that specifies athletes age\n",
    "  tot_col: The column name that specifies athletes total\n",
    "  sex_col: The column name that specifies the athletes sex\n",
    "  bw_col: The column name that specifies the athletes body weight\n",
    "  wc_col: The column name that specifies the athletes weight class\n",
    "  \"\"\"\n",
    "  BW_sinclair = []\n",
    "  WC_sinclair = []\n",
    "  #Mst_sinclair = [] #Removed as the masters federations no longer use this\n",
    "  Q_points = [] #We are only going by weightclass for now as our assocuation only uses Sinclair\n",
    "  Q_masters = []\n",
    "  #Will need to add BW Q-masters here into this dataframe\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  upd_rownum = upd_sheet.shape[0]\n",
    "  #print(\"Row number:\", upd_rownum)\n",
    "  #Setting up which rows to skip ie what strings are missing what we need in the correct form\n",
    "  skip_row = []\n",
    "  for j in range(upd_rownum):\n",
    "    try:\n",
    "      ath_age = float(upd_sheet.loc[j, age_col])\n",
    "      ath_total = float(upd_sheet.loc[j, tot_col])\n",
    "      ath_sex = str(upd_sheet.loc[j, sex_col])\n",
    "      ath_BW = float(upd_sheet.loc[j, bw_col])\n",
    "      ath_wtcl = str(upd_sheet.loc[j, wc_col])\n",
    "    except:\n",
    "      skip_row.append(j)\n",
    "  #print(skip_row)\n",
    "  #Update the values\n",
    "  for i in range(upd_rownum):\n",
    "    if i in skip_row: #Append nan for what will not complete\n",
    "      #print(i)\n",
    "      BW_sinclair.append(np.nan)\n",
    "      WC_sinclair.append(np.nan)\n",
    "      #Mst_sinclair.append('NaN')\n",
    "      Q_points.append(np.nan)\n",
    "      Q_masters.append(np.nan)\n",
    "    else: #If we can, run the normal loop\n",
    "      ath_age = float(upd_sheet.loc[i, age_col])\n",
    "      ath_total = float(upd_sheet.loc[i, tot_col])\n",
    "      ath_sex = str(upd_sheet.loc[i, sex_col])\n",
    "      #print(ath_sex)\n",
    "      ath_BW = float(upd_sheet.loc[i, bw_col])\n",
    "      ath_wtcl = str(upd_sheet.loc[i, wc_col])\n",
    "      #print(ath_wtcl)\n",
    "      if '+' in ath_wtcl: #Set up so we can use appropriate sinclair for heavyweight\n",
    "        sin = 1\n",
    "      else:\n",
    "        sin = 0\n",
    "        ath_wtcl = float(ath_wtcl)\n",
    "      if ath_sex == 'M':\n",
    "        BW_sinclair.append(sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Men']), float(sinclair_table.loc[1, 'Men'])))\n",
    "        Q_points.append(q_points_male(ath_total, ath_BW))\n",
    "        #print(sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Men']), float(sinclair_table.loc[1, 'Men'])))\n",
    "        #print(q_points_male(ath_total, ath_BW))\n",
    "        #Append weight class sinclair\n",
    "        if sin == 0:\n",
    "          WC_sinclair.append(sinclair_total(ath_total, float(ath_wtcl), float(sinclair_table.loc[0, 'Men']), float(sinclair_table.loc[1, 'Men'])))\n",
    "        elif sin == 1:\n",
    "          WC_sinclair.append(ath_total)\n",
    "        else:\n",
    "          WC_sinclair.append(np.nan)\n",
    "        #Append masters Q points if nessisary\n",
    "        if ath_age >= 30:\n",
    "          #5 #Place holder number\n",
    "          scale_factM = scale_factor_locator(Q_agef_sheet, ath_age, 'M')\n",
    "          qM_masters_val = q_points_male(ath_total, ath_BW) * scale_factM\n",
    "          Q_masters.append(qM_masters_val)\n",
    "          #age_const_val_m = age_constant_selector(masters_men_table, 'Age_low', 'Age_high', 'Age_coefficient', ath_age)\n",
    "          #Mst_sinclair.append(masters_sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Men']), float(sinclair_table.loc[1, 'Men']), age_const_val_m, ath_age))\n",
    "        else:\n",
    "          #5\n",
    "          Q_masters.append(np.nan)\n",
    "          #Mst_sinclair.append('NaN')\n",
    "      elif ath_sex == 'W':\n",
    "        BW_sinclair.append(sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Woman']), float(sinclair_table.loc[1, 'Woman'])))\n",
    "        Q_points.append(q_points_female(ath_total, ath_BW))\n",
    "        #print(sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Men']), float(sinclair_table.loc[1, 'Men'])))\n",
    "        #print(q_points_female(ath_total, ath_BW))\n",
    "        if sin == 0:\n",
    "          WC_sinclair.append(sinclair_total(ath_total, ath_wtcl, float(sinclair_table.loc[0, 'Woman']), float(sinclair_table.loc[1, 'Woman'])))\n",
    "        elif sin == 1:\n",
    "          WC_sinclair.append(ath_total)\n",
    "        else:\n",
    "          WC_sinclair.append(np.nan)\n",
    "        if ath_age >= 30:\n",
    "          #5\n",
    "          scale_factF = scale_factor_locator(Q_agef_sheet, ath_age, 'F')\n",
    "          qF_masters_val = q_points_female(ath_total, ath_BW) * scale_factF\n",
    "          Q_masters.append(qF_masters_val)\n",
    "          #age_const_val_w = age_constant_selector(masters_woman_table, 'Age_low', 'Age_high', 'Age_coefficient', ath_age)\n",
    "          #Mst_sinclair.append(masters_sinclair_total(ath_total, ath_BW, float(sinclair_table.loc[0, 'Woman']), float(sinclair_table.loc[1, 'Woman']), age_const_val_w, ath_age))\n",
    "        else:\n",
    "          #5\n",
    "          Q_masters.append(np.nan)\n",
    "        # Mst_sinclair.append('NaN')\n",
    "      else:\n",
    "        BW_sinclair.append(np.nan)\n",
    "        WC_sinclair.append(np.nan)\n",
    "        #print(np.nan)\n",
    "        #print(np.nan)\n",
    "        #Mst_sinclair.append('NaN')\n",
    "        Q_points.append(np.nan)\n",
    "        Q_masters.append(np.nan)\n",
    "  upd_sheet[Bw_sinc_col] = BW_sinclair\n",
    "  upd_sheet[WC_sinc_col] = WC_sinclair\n",
    "  #upd_sheet['Masters_Sinclair'] = Mst_sinclair\n",
    "  upd_sheet[Q_col] = Q_points\n",
    "  upd_sheet[Q_mst_col] = Q_masters\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  skip_row = [] #Reset just in case\n",
    "  return upd_sheet\n",
    "\n",
    "def class_adder(upd_sheet, mens_class_sheet, womans_class_sheet, age_col, tot_col, sex_col, bw_col, wc_col, group_col, class_col):\n",
    "  \"\"\"\n",
    "  Adds the athletes class to the sheet\n",
    "\n",
    "  mens_class_sheet: The mens classification sheet\n",
    "  womans_class_sheet: The womens classification sheet\n",
    "  upd_sheet: The sheet we are updating and adding the athletes age to\n",
    "  age_col: The column name that that specifies athletes age\n",
    "  tot_col: The column name that specifies athletes total\n",
    "  sex_col: The column name that specifies the athletes sex\n",
    "  bw_col: The column name that specifies the athletes body weight\n",
    "  wc_col: The column name that specifies the athletes weight class\n",
    "  group_col: The column name we want to add to the sheet for the age group\n",
    "  class_col: The column name we want to add to the sheet for classification\n",
    "  \"\"\"\n",
    "  #Set the catagories and classes\n",
    "  jr_cats = ['Jr. Nats', 'Next Gen. Elite'] #Note that we may need to remove the space here\n",
    "  sr_comp_groups = ['SR', 'MST']\n",
    "  cols_to_remove = ['Category', 'Marker']\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  upd_rownum = upd_sheet.shape[0]\n",
    "  #Figure out the columns we need to skip\n",
    "  skip_row = []\n",
    "  for j in range(upd_rownum):\n",
    "    try:\n",
    "      ath_age = float(upd_sheet.loc[j, age_col])\n",
    "      ath_total = float(upd_sheet.loc[j, tot_col])\n",
    "      ath_sex = str(upd_sheet.loc[j, sex_col])\n",
    "      ath_BW = float(upd_sheet.loc[j, bw_col])\n",
    "      ath_wtcl = str(upd_sheet.loc[j, wc_col])\n",
    "    except:\n",
    "      skip_row.append(j)\n",
    "  #Appending the classes\n",
    "  classes = []\n",
    "  for i in range(upd_rownum):\n",
    "    if i in skip_row: #Append nan for what will not complete\n",
    "      #print(i)\n",
    "      classes.append('NaN')\n",
    "    else: #If we can, run the normal loop\n",
    "      ath_age = float(upd_sheet.loc[i, age_col])\n",
    "      ath_total = float(upd_sheet.loc[i, tot_col])\n",
    "      ath_sex = upd_sheet.loc[i, sex_col]\n",
    "      ath_BW = float(upd_sheet.loc[i, bw_col])\n",
    "      ath_wtcl = upd_sheet.loc[i, wc_col]\n",
    "      ath_comp_group = upd_sheet.loc[i, group_col]\n",
    "      if ath_sex == 'M':\n",
    "          Msheet_to_det = (mens_class_sheet[mens_class_sheet['Category'] == ath_wtcl])\n",
    "          Msheet_to_det = Msheet_to_det.drop(['Category'], axis=1) #Dont need this any more after weightclass selected\n",
    "          pref_class = list(Msheet_to_det.columns)\n",
    "          if ath_comp_group in sr_comp_groups:\n",
    "            Msheet_to_det =  Msheet_to_det.drop(jr_cats, axis=1)\n",
    "            pref_class = list(Msheet_to_det.columns)\n",
    "          Msheet_to_det = (Msheet_to_det[pref_class]).reset_index(drop=True)\n",
    "          if Msheet_to_det.shape[0] == 0:\n",
    "            classes.append('NaN')\n",
    "          else:\n",
    "            for j in range(len(pref_class)-1):\n",
    "              classif_b = list((Msheet_to_det.columns))[j]\n",
    "              classif_t = list((Msheet_to_det.columns))[j+1]\n",
    "              val_bot = float(Msheet_to_det.loc[0, classif_b])\n",
    "              val_top = float(Msheet_to_det.loc[0, classif_t])\n",
    "              if (classif_b == 'Novice') & (val_bot > ath_total):\n",
    "                classes.append(classif_b)\n",
    "                break\n",
    "              elif (classif_t == 'Elite') & (val_top < ath_total):\n",
    "                classes.append(classif_t)\n",
    "                break\n",
    "              elif val_bot <= ath_total < val_top:\n",
    "                classes.append(classif_b)\n",
    "                break\n",
    "      elif ath_sex == 'W':\n",
    "        Wsheet_to_det = (womans_class_sheet[womans_class_sheet['Category'] == ath_wtcl])\n",
    "        Wsheet_to_det = Wsheet_to_det.drop(['Category'], axis=1)\n",
    "        pref_class = list(Wsheet_to_det.columns)\n",
    "        if ath_comp_group in sr_comp_groups:\n",
    "          Wsheet_to_det =  Wsheet_to_det.drop(jr_cats, axis=1)\n",
    "          pref_class = list(Wsheet_to_det.columns)\n",
    "        Wsheet_to_det = (Wsheet_to_det[pref_class]).reset_index(drop=True)\n",
    "        if Wsheet_to_det.shape[0] == 0:\n",
    "          classes.append('NaN')\n",
    "        else:\n",
    "          for j in range(len(pref_class)-1):\n",
    "            classif_b = list((Wsheet_to_det.columns))[j]\n",
    "            classif_t = list((Wsheet_to_det.columns))[j+1]\n",
    "            val_bot = float(Wsheet_to_det.loc[0, classif_b])\n",
    "            val_top = float(Wsheet_to_det.loc[0, classif_t])\n",
    "            if (classif_b == 'Novice') & (val_bot > ath_total):\n",
    "              classes.append(classif_b)\n",
    "              break\n",
    "            elif (classif_t == 'Elite') & (val_top < ath_total):\n",
    "              classes.append(classif_t)\n",
    "              break\n",
    "            elif val_bot <= ath_total < val_top:\n",
    "              classes.append(classif_b)\n",
    "              break\n",
    "  upd_sheet[class_col] = classes\n",
    "  upd_sheet = upd_sheet.reset_index(drop=True)\n",
    "  return upd_sheet\n",
    "\n",
    "def srjryth_rem(df, colname):\n",
    "  \"\"\"\n",
    "  Removes the group entery from the catagory column in the cleaining\n",
    "\n",
    "  df: The dataframe we want to remove the group from\n",
    "  colname: The name of the column we want to remove the group from\n",
    "  \"\"\"\n",
    "  new_col = []\n",
    "  df = df.reset_index(drop=True)\n",
    "  upd_rownum = df.shape[0]\n",
    "  for i in range(upd_rownum):\n",
    "    cat_in_q = str(df.loc[i, colname])\n",
    "    #print(cat_in_q)\n",
    "    if \"SR\" in cat_in_q:\n",
    "      new_col.append(cat_in_q.replace(\"SR \", \"\")) #The extra space gets rid of any error when the next function happens\n",
    "    elif \"MST\" in cat_in_q:\n",
    "      new_col.append(cat_in_q.replace(\"MST \", \"\"))\n",
    "    elif \"JR\" in cat_in_q:\n",
    "      new_col.append(cat_in_q.replace(\"JR \", \"\"))\n",
    "    elif \"YTH\" in cat_in_q:\n",
    "      new_col.append(cat_in_q.replace(\"YTH \", \"\"))\n",
    "    else:\n",
    "      new_col.append(cat_in_q)\n",
    "  df[colname] = new_col\n",
    "  return df\n",
    "\n",
    "def sex_cleaner(df, sex_col):\n",
    "  \"\"\"\n",
    "  Quality controls the sex column to prevent errors down the line\n",
    "\n",
    "  df: The dataframe we want to clean\n",
    "  sex_col: The name of the column we want to clean\n",
    "  \"\"\"\n",
    "  df = df.reset_index(drop=True)\n",
    "  upd_rownum = df.shape[0]\n",
    "  new_col = []\n",
    "  for i in range(upd_rownum):\n",
    "    sex_in_q = str(df.loc[i, sex_col])\n",
    "    if 'M' in sex_in_q:\n",
    "      new_col.append('M')\n",
    "    elif 'F' in sex_in_q:\n",
    "      new_col.append('F')\n",
    "    elif 'W' in sex_in_q:\n",
    "      new_col.append('W')\n",
    "    else:\n",
    "      new_col.append(np.nan)\n",
    "  df[sex_col] = new_col\n",
    "  return df\n",
    "\n",
    "def upd_dict_infoadd(upd_dict, sinc_const_sheet, m_class_sheet, f_class_sheet):\n",
    "  \"\"\"\n",
    "  Adds all of the unformation to the update dictionarys that we need to update both the records and rankings sheets\n",
    "\n",
    "  upd_dict: The dictionary of update dataframes\n",
    "  sinc_const_sheet: The sinclair constant sheet\n",
    "  m_class_sheet: The mens classification sheet\n",
    "  f_class_sheet: The womens classification sheet\n",
    "  \"\"\"\n",
    "  new_dict = {}\n",
    "  upd_dict_keys = list(upd_dict.keys())\n",
    "  for key in upd_dict_keys:\n",
    "    print(key)\n",
    "    #Get everything ready for some spicey manipulations\n",
    "    date, comp = key.split(\"_\")\n",
    "    df = upd_dict[key].reset_index(drop=True)\n",
    "    #Add the current age of the athlete\n",
    "    compage_col = 'Comp_Age'\n",
    "    year_of_birth_col = 'YOB'\n",
    "    df = comp_age_adder(df, date, 'Born',  compage_col, year_of_birth_col)\n",
    "    #Add the athlete catagory if it is not already in the dataframe\n",
    "    cat_add_colname = 'Group'\n",
    "    if cat_add_colname not in list(df.columns):\n",
    "      df = catagory_adder(df, compage_col, cat_add_colname)\n",
    "    #Add the masters age catagory for all masters lifters\n",
    "    mast_agecol = \"Mst_Age\"\n",
    "    mst_agewinds = [30, 35, 40, 45, 45, 50, 55, 60, 65, 70, 75, 80, 85, float('inf')]\n",
    "    df = mst_ageadd(df, cat_add_colname, mast_agecol, mst_agewinds, compage_col)\n",
    "    #Generate seperate sex and weightclass col we assume that\n",
    "    sex_col = 'Sex'\n",
    "    wc_col = 'W.C.'\n",
    "    if 'Cat' in list(df.columns):\n",
    "      df = srjryth_rem(df, 'Cat')\n",
    "    try:\n",
    "      df = col_seperater_space(df, sex_col, wc_col, 'Cat')\n",
    "    except:\n",
    "      df[sex_col] = df['Cat']\n",
    "      df = sex_cleaner(df, sex_col) #Literally bc it already exist for the masters so we will just clean it up\n",
    "      #df = MFW_seperator(df, sex_col, wc_col, 'Cat') #Assume the error is caused by no space in the cat col so we are ging to do manually\n",
    "    df[wc_col] = df[wc_col].astype(str) #This is because we will get NaNs in the next line of code that we do not want if we do not do this\n",
    "    df = WC_clean(df, wc_col, True) #Replace for the new coluumn\n",
    "    df = WC_clean(df, 'Cat', True) #Replace for the old\n",
    "    df = sex_cleaner(df, sex_col) #Does repleat for masters which is ok here\n",
    "    #Generates the proper column\n",
    "    prop_cantname = \"Prop_cat\"\n",
    "    df = clean_cat_col(df, cat_add_colname, sex_col, wc_col, mast_agecol, prop_cantname)\n",
    "    #print(df)\n",
    "    #Adding the sinclare score if it does not exist\n",
    "    #print(df[\"Total\"]) #print(df[\"Sex\"]) #print(df[\"W.C.\"]) #print(df[\"B.W.\"]) #print(df[\"Comp_age\"])\n",
    "    bw_col = \"B.W.\"\n",
    "    tot_col = \"Total\"\n",
    "    df = sinclair_Q_adder(df, sinc_const_sheet, Q_agef_sheet, \"BW_Q-points\", \"BW_Q-masters\", \"WC_Sinclair\", \"BW_Sinclair\",  compage_col, tot_col, sex_col, bw_col, wc_col)\n",
    "    #print(df[\"BW_Q-points\"]) #print(df[\"BW_Q-masters\"] #print(df[\"WC_Sinclair\"]) #print(df[\"BW_Sinclair\"])\n",
    "    #Add the athletes classes\n",
    "    class_col = \"Qualification_Standard\"\n",
    "    group_col = \"Group\"\n",
    "    df = class_adder(df, m_class_sheet, f_class_sheet, compage_col, tot_col, sex_col, bw_col, wc_col, group_col, class_col)\n",
    "    #Adding the comp date and name to the actual dataframe\n",
    "    df[\"Comp_Date\"] = date\n",
    "    df[\"Comp_Name\"] = comp\n",
    "    #One very simple update\n",
    "    last_name_col = \"Last_Name\"\n",
    "    df[last_name_col] = df[last_name_col].str.upper()\n",
    "    #Dropping all 98 weightclass values\n",
    "    df = df[df[wc_col] != '98']\n",
    "    df = df[df[wc_col] != 98]\n",
    "    #Adding the sheet to the dictionary\n",
    "    new_dict[key] = df\n",
    "  #Returning the updated dictionary with the information\n",
    "  return new_dict\n",
    "\n",
    "\n",
    "#Functions to update the ranking sheets\n",
    "\n",
    "def rank_adder(df, rank_cname):\n",
    "  \"\"\"\n",
    "  Adds the rank column to the dataframe\n",
    "\n",
    "  df: The dataframe we want to add the rank column to\n",
    "  rank_cname: The name of the column we want to add for rank\n",
    "  \"\"\"\n",
    "  if rank_cname in list(df.columns): #Get rid of the old column\n",
    "    df = df.drop(rank_cname, axis=1)\n",
    "  df = df.reset_index(drop=True)\n",
    "  rank_col = []\n",
    "  for i in range(1, df.shape[0] + 1):\n",
    "    rank_col.append(i)\n",
    "  df.insert(0, \"Rank\", rank_col) #Makes sure that the rank is at the front of the dataframe\n",
    "  return df\n",
    "\n",
    "def duplicate_remover(df, firstname_colname, lastname_colname, wtclass_colname, rank_col):\n",
    "  \"\"\"\n",
    "  Builds a dataframe that has highest entery for a person by weightclass\n",
    "  Basically, this function removes all of the unessisary duplicates in the rankings sheet\n",
    "  Ensure the relevant columns have a consistent format (strings for names, weight class) or this function will not work as good as you need\n",
    "\n",
    "  df: The dataframe we are doing this operation on\n",
    "  firstname_colname: The name of the first name column\n",
    "  lastname_colname: The name of the last name column\n",
    "  wtclass_colname: The name of the weight class column\n",
    "  rank_col: The name of the column that we have used for rankings\n",
    "  \"\"\"\n",
    "  df[firstname_colname] = (df[firstname_colname].astype(str)).str.strip()\n",
    "  df[lastname_colname] = (df[lastname_colname].astype(str)).str.strip()\n",
    "  df[wtclass_colname] = (df[wtclass_colname].astype(str)).str.strip()\n",
    "  df[rank_col] = pd.to_numeric(df[rank_col], errors='coerce')  #Ensure rank is numeric\n",
    "  #Sort the DataFrame by rank_col in descending order (higher ranks come first)\n",
    "  df_sorted = df.sort_values(by=rank_col, ascending=False)\n",
    "  #Drop duplicates based on the combination of firstname, lastname, and wtclass\n",
    "  #Keeps the first occurrence (highest rank due to sorting)\n",
    "  cleaned_df = df_sorted.drop_duplicates(subset=[firstname_colname, lastname_colname, wtclass_colname], keep='first').reset_index(drop=True)\n",
    "  return cleaned_df\n",
    "\n",
    "def rankings_updator(rank_to_upd, upd_dict, rank_col, sex_col, upd_keyname_dict, date_soon, date_end): #m_ranksheet_name, f_ranksheet_name\n",
    "  \"\"\"\n",
    "  Updates the rankings sheets in the rank_to_upd dictionary by the rank col\n",
    "  We add from all of the competitions in the update dictionary\n",
    "\n",
    "  rank_to_update: The dictionary that contains the current rankings before the updates\n",
    "  upd_dict: The dictionary that contains the competitions sheets to add\n",
    "  rank_col: The column we want to do the ranking by\n",
    "  update_keyname_dict: The dictionary that specifies what key goes with male, female, and other oprientation rankings in the current ranking dictionary.\n",
    "                       This key name is usually the sheet name in the rankings dictionary\n",
    "  date_soon: The earlies date we want to include in the sheet\n",
    "  date_end: The latest date we want to include in the sheet\n",
    "  \"\"\"\n",
    "  #Getting the needed information and sheets from the current rankings sheet\n",
    "  curr_male_ranks = rank_to_upd[upd_keyname_dict['Male_Ranks']]\n",
    "  curr_male_cnames = list(curr_male_ranks.columns)\n",
    "  curr_female_ranks = rank_to_upd[upd_keyname_dict['Female_Ranks']]\n",
    "  curr_female_cnames = list(curr_female_ranks.columns)\n",
    "  #Setting up the update dictionary to be in the correct form to be incorperated into the current rankings\n",
    "  upd_stacked = pd.concat(upd_dict.values(), ignore_index=True)\n",
    "  #Filtering to only contain the dates we want\n",
    "  #upd_stacked['Comp_Date'] = pd.to_datetime(upd_stacked['Comp_Date'])\n",
    "  #upd_stacked['Comp_Date'] = upd_stacked['Comp_Date'].dt.date\n",
    "  upd_stacked[rank_col] = upd_stacked[rank_col].astype(float)\n",
    "  upd_stacked = upd_stacked[upd_stacked['Comp_Date'] >= date_soon]\n",
    "  upd_stacked = upd_stacked[upd_stacked['Comp_Date'] <= date_end]\n",
    "  #upd_stacked = upd_stacked.reset_index(drop=True) #Doing just in case\n",
    "  upd_male = upd_stacked[upd_stacked[sex_col] == 'M'].reset_index(drop=True)\n",
    "  unrm_male = upd_male[curr_male_cnames].dropna(subset=[rank_col])\n",
    "  upd_female = upd_stacked[upd_stacked[sex_col] == 'W'].reset_index(drop=True)\n",
    "  unrf_female = upd_female[curr_female_cnames].dropna(subset=[rank_col])\n",
    "  #Organizing and cleaning for the new rankings\n",
    "  #Male\n",
    "  male_stacked = pd.concat([curr_male_ranks, unrm_male], axis=0, ignore_index=True)\n",
    "  male_sorted = male_stacked.sort_values(by=rank_col, ascending=False)\n",
    "  male_no_dups = duplicate_remover(male_sorted, \"First_Name\", \"Last_Name\", \"W.C.\", rank_col)\n",
    "  male_ranked = rank_adder(male_no_dups, \"Rank\").reset_index(drop=True)\n",
    "  male_ranked[\"Total\"] = male_ranked[\"Total\"].astype(int) #Some last minute cleaning\n",
    "  male_ranked[rank_col] = male_ranked[rank_col].round(2)\n",
    "  #Female\n",
    "  female_stacked = pd.concat([curr_female_ranks, unrf_female], axis=0, ignore_index=True)\n",
    "  female_sorted = female_stacked.sort_values(by=rank_col, ascending=False)\n",
    "  female_no_dups = duplicate_remover(female_sorted, \"First_Name\", \"Last_Name\", \"W.C.\", rank_col)\n",
    "  female_ranked = rank_adder(female_no_dups, \"Rank\").reset_index(drop=True)\n",
    "  female_ranked[\"Total\"] = female_ranked[\"Total\"].astype(int) #Some last minute cleaning\n",
    "  female_ranked[rank_col] = female_ranked[rank_col].round(2)\n",
    "  #print(female_ranked)\n",
    "  #Return the new updated dataframe\n",
    "  rank_to_upd[upd_keyname_dict['Male_Ranks']] = male_ranked\n",
    "  rank_to_upd[upd_keyname_dict['Female_Ranks']] = female_ranked\n",
    "  return rank_to_upd\n",
    "\n",
    "def upd_inx_dict(col_list):\n",
    "  \"\"\"\n",
    "  Builds the dictionary that assignes the column names with the index so we can update the correct values\n",
    "\n",
    "  col_list: The list of column names we want to update\n",
    "  \"\"\"\n",
    "  upd_dict = {}\n",
    "  alphabet = [\"A\",\"B\",\"C\",\"D\",\"E\",\"F\",\"G\",\"H\",\"I\",\"J\",\"K\",\"L\",\"M\",\"N\",\"O\",\"P\",\"Q\",\"R\",\"S\",\"T\",\"U\",\"V\",\"W\",\"X\",\"Y\",\"Z\"]\n",
    "  for i in range(len(col_list)):\n",
    "    upd_dict[col_list[i]] =  alphabet[i]\n",
    "  return upd_dict\n",
    "\n",
    "def rank_sheet_update(pathID, subsheet, replace_sheet, row_start, quota):\n",
    "  \"\"\"\n",
    "  Updates the rankings sheet in the google sheet\n",
    "\n",
    "  pathID: The file id of the .gsheet files or the full path of the .xlxs file\n",
    "  subsheet: The subsheet we want to update and replace\n",
    "  auth: Specifies if we need to remount to the drive or authenticate the user for the google sheet upload. \"True\" Means that we do\n",
    "  replace_sheet: The sheet we want to update the corrent records with\n",
    "  row_start: The row we want to start updating from in the update sheet\n",
    "  quota: The amount of cells we can update per minute, stupid google\n",
    "\n",
    "  This is a very usefull think for the back half of the function https://www.youtube.com/watch?v=cN7W2EPM-dw\n",
    "  This is also very useful if you like reading https://docs.gspread.org/en/latest/index.html\n",
    "  \"\"\"\n",
    "  #Set needed packages\n",
    "  from google.colab import auth\n",
    "  import google.auth\n",
    "  #Authenticate and open the sheet\n",
    "  auth.authenticate_user()\n",
    "  creds, _ = google.auth.default()\n",
    "  gc = gspread.authorize(creds)\n",
    "  sheet_file = gc.open_by_key(pathID).worksheet(subsheet) #Open the very specific worksheet\n",
    "  #Updating the first row with the update date and time (Note we get lucky and it keeps the origional format)\n",
    "  col_date_name = \"Updated as of: \" + str(datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "  sheet_file.update([[col_date_name]], \"A1\")\n",
    "  #Updating the meat of the dataframe\n",
    "  values_list = list(sheet_file.row_values(2))\n",
    "  upd_dict = upd_inx_dict(values_list)\n",
    "  count = 0\n",
    "  print(\"Updating \", subsheet)\n",
    "  for val in values_list:\n",
    "    upd_els = list(replace_sheet[val]) #Note that we assume that the column names for the dataframe are the same as list we want to update\n",
    "    col_ind = upd_dict[val]\n",
    "    for i in range(len(upd_els)):\n",
    "      update_indx = str(col_ind + str(row_start+i))\n",
    "      sheet_file.update_acell(update_indx, upd_els[i])\n",
    "      count += 1\n",
    "      if count == quota:\n",
    "        print(\"Taking a 60 second pause to stay under the quota\")\n",
    "        time.sleep(60)\n",
    "        count = 0\n",
    "  print(subsheet, \" updated\")\n",
    "\n",
    "\n",
    "#Some extra functions that may be used\n",
    "\n",
    "def list_string_split(the_list, split_el, num_seps):\n",
    "  \"\"\"\n",
    "  Splits all strings in a list of strings by another string\n",
    "\n",
    "  list: The list of strings we want to split\n",
    "  split_el: The string we want to split the strings by\n",
    "  num_seps: The number of times we want to split the string, Note that it goes from front to back on where it splits\n",
    "  \"\"\"\n",
    "  new_list = []\n",
    "  for i in range(len(the_list)):\n",
    "    new_list.append(the_list[i].split(split_el, num_seps))\n",
    "  return new_list\n",
    "\n",
    "def list_unpacker(the_list, sub_el_index):\n",
    "  \"\"\"\n",
    "  This function makes a new list of a specified element of a sublist in a list of list\n",
    "\n",
    "  the_list: The list of lists we want to unpack\n",
    "  sub_el_index: The index of the element we want to unpack\n",
    "  \"\"\"\n",
    "  new_list = []\n",
    "  for i in range(len(the_list)):\n",
    "    new_list.append(the_list[i][sub_el_index])\n",
    "  return new_list\n",
    "\n",
    "def rankings_seperator(df, age_group_colname, age_groups):\n",
    "  \"\"\"\n",
    "  Breaks up a rankings sheet into groups\n",
    "\n",
    "  df: The dataframe we want to break up\n",
    "  age_group_colnames: The column name that specifies the age groups\n",
    "  age_groups: The age groups within the age group column names that we want to sperate the data frame into\n",
    "  \"\"\"\n",
    "  df_split = df[df[age_group_colname].isin(age_groups)]\n",
    "  df_split = df_split.reset_index(drop=True)\n",
    "  df_split = df_split.drop('Rank', axis=1)\n",
    "  df_split = rank_adder(df_split)\n",
    "  df_split = df_split.drop(age_group_colname, axis=1)\n",
    "  return df_split\n",
    "\n",
    "\n",
    "#Code to update records sheets\n",
    "\n",
    "def class_cat_dbuild(sheet_names, cat_clases):\n",
    "  \"\"\"\n",
    "  Builds the dictionary that assignes the name of the sheet with the category\n",
    "\n",
    "  sheet_names: The record sheet names as defined above\n",
    "  class_cat: The class catagories as defined as follows. 'YTH_W':... , 'YTH_M':... , 'JR_W':... , 'JR_M':... , 'SR_W':... , 'SR_M':... , 'MST_M':... , 'MST_W':...\n",
    "  \"\"\"\n",
    "  class_sheet_dict = {}\n",
    "  for i in range(len(sheet_names)):\n",
    "    class_sheet_dict[cat_clases[i]] = sheet_names[i]\n",
    "  return class_sheet_dict\n",
    "\n",
    "def list_string_split(the_list, split_el, num_seps):\n",
    "  \"\"\"\n",
    "  Splits all strings in a list of strings by another string\n",
    "\n",
    "  list: The list of strings we want to split\n",
    "  split_el: The string we want to split the strings by\n",
    "  num_seps: The number of times we want to split the string, Note that it goes from front to back on where it splits\n",
    "  \"\"\"\n",
    "  new_list = []\n",
    "  for i in range(len(the_list)):\n",
    "    new_list.append(the_list[i].split(split_el, num_seps))\n",
    "  return new_list\n",
    "\n",
    "def list_unpacker(the_list, sub_el_index):\n",
    "  \"\"\"\n",
    "  This function makes a new list of a specified element of a sublist in a list of list\n",
    "\n",
    "  the_list: The list of lists we want to unpack\n",
    "  sub_el_index: The index of the element we want to unpack\n",
    "  \"\"\"\n",
    "  new_list = []\n",
    "  for i in range(len(the_list)):\n",
    "    new_list.append(the_list[i][sub_el_index])\n",
    "  return new_list\n",
    "\n",
    "def date_key_sort(the_keys, orderd_dates):\n",
    "  \"\"\"\n",
    "  Sorts the list of dataframe keys for the updated competitions from soonest to latest\n",
    "\n",
    "  the_keys: The keys we want to sort\n",
    "  orderd_dates: The list of dates we want to order the keys by\n",
    "  \"\"\"\n",
    "  new_keys = []\n",
    "  for date in orderd_dates:\n",
    "    for key in the_keys:\n",
    "      if date in key:\n",
    "        new_keys.append(key)\n",
    "  return new_keys\n",
    "\n",
    "def proper_null_convert(df, col_list):\n",
    "  \"\"\"\n",
    "  Converts all of the columns that have null lifts into the proper form to compute the records\n",
    "\n",
    "  df: The dataframe we want to do this form\n",
    "  col_list: The list of columns we want to convert\n",
    "  \"\"\"\n",
    "  pattern = r\"\\(\\d+\\)\"\n",
    "  for col in col_list:\n",
    "    if df[col].astype(str).str.contains(pattern, na=False).any(): #Updates if it exist in the dataframe\n",
    "      df.loc[:,col] = df[col].str.replace(r\"\\((\\d+)\\)\", r\"-\\1\", regex=True) #Note that we can add more forms to this function as we come across more\n",
    "      df.loc[:,col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    else: #Note that we will likely have to update this function as we get more cases of no lifts that are not negaitives\n",
    "      df.loc[:,col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "  return df\n",
    "\n",
    "def max_min_finder(df, col_list):\n",
    "  \"\"\"\n",
    "  Finds the min and max lift in each comp to save us some itterations when we go through the sheet for records\n",
    "  Note that this uses the absolute values of each one\n",
    "\n",
    "  df: The dataframe we want to do this form\n",
    "  col_list: The list of columns we want to finds the min and max lifts for\n",
    "  \"\"\"\n",
    "  max_val = 0 #float('-inf')\n",
    "  min_val = float('inf')\n",
    "  for col in col_list:\n",
    "    nums_to_test = list(df[col])\n",
    "    for num in nums_to_test:\n",
    "      if isinstance(num, (int, float)) == False:\n",
    "        continue\n",
    "      if abs(num) > max_val:\n",
    "        max_val = abs(num)\n",
    "      if abs(num) < min_val:\n",
    "        min_val = abs(num)\n",
    "  return min_val, max_val\n",
    "\n",
    "def rec_filt_error(df):\n",
    "  \"\"\"\n",
    "  Stops the code if the record sheet is not filterd for a single error\n",
    "\n",
    "  df: The record datasheet we want to pull the error on\n",
    "  \"\"\"\n",
    "  assert df.shape[0] == 1, \"The record sheet is not filtering for a single record\"\n",
    "\n",
    "def brac_rec_rem(el):\n",
    "  \"\"\"\n",
    "  Puts the record into the correct form to be compared with the athletes made attempt\n",
    "\n",
    "  el: The element we want to convert to the correct form\n",
    "  \"\"\"\n",
    "  el_type = type(el)\n",
    "  if el_type == int:\n",
    "    return el\n",
    "  elif el_type == str:\n",
    "    if \"[\" in el:\n",
    "      el = el.replace(\"[\", \"\")\n",
    "    if \"]\" in el:\n",
    "      el = el.replace(\"]\", \"\")\n",
    "      #Note that we will need to add more cases as they come\n",
    "    return int(el)\n",
    "  else:\n",
    "    raise ValueError(f\"Unsupported element type: {el_type}\")\n",
    "\n",
    "def update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key, last_name, first_name, corg_val, wc_val, lift, club, the_try, comp_name, comp_date):\n",
    "  \"\"\"\n",
    "  Updates the record sheet with the nessisary information\n",
    "\n",
    "  clean_sheet: The sheet we want to update the records from\n",
    "  rec_dic: The dictionary of the current records sheets\n",
    "  class_sheet_dict: The dictionary that lets us know what records sheet goes with what category\n",
    "  last_name: The athlete last name\n",
    "  first_name: The athlete first name\n",
    "  corg_val: The category value we need to put in to the right record sheet\n",
    "  wc_val: The weight class value we need to put in to the right record sheet\n",
    "  lift: The lift we are doing the records updates for\n",
    "  club: The club we are doing the records updates for\n",
    "  the_try: The attempt we are doing the records updates for\n",
    "  comp_name: The name of the competition we are doing the records updates for\n",
    "  comp_date: The date of the competition we are doing the records updates for\n",
    "  \"\"\"\n",
    "  rsheet_in_q = rec_dic[class_sheet_dic[rsheet_key]]\n",
    "  rsheet_in_q = rsheet_in_q.reset_index(drop = True)\n",
    "  #print(corg_val, wc_val, lift)\n",
    "  mst_upd_sheet = rsheet_in_q[(rsheet_in_q[\"Category\"] == corg_val) & (rsheet_in_q[\"Weight Cat.\"] == wc_val) & (rsheet_in_q[\"Lift\"] == lift)]\n",
    "  rec_filt_error(mst_upd_sheet) #Making sure there are no problems here\n",
    "  row_index = mst_upd_sheet.index.tolist()[0]\n",
    "  rec_val = mst_upd_sheet.loc[row_index, \"Record\"]\n",
    "  rec_val = brac_rec_rem(rec_val)\n",
    "  if rec_val < the_try: #Append the new record and add to the historical reccords\n",
    "    replacement_row = {'Category':corg_val, 'Weight Cat.':wc_val, 'Lift':lift, 'Last Name':last_name,\n",
    "                       'First Name':first_name, 'Club':club, 'Record':int(the_try), 'Event':comp_name,\n",
    "                       'Location':np.nan, 'Date':comp_date}\n",
    "    rsheet_in_q.loc[row_index] = replacement_row\n",
    "    rec_dic[class_sheet_dic[rsheet_key]] = rsheet_in_q #Replace the value in the sheet\n",
    "    hist_frame = rec_dic[class_sheet_dic['HIST']]\n",
    "    new_hist_frame = pd.concat([hist_frame, mst_upd_sheet], ignore_index=True).reset_index(drop = True) #Note that we will sort after\n",
    "    rec_dic[class_sheet_dic['HIST']] = new_hist_frame\n",
    "  return rec_dic\n",
    "\n",
    "def reccord_sequence(rec_dic, clean_sheet, min_val, max_val, wt_clsses, class_sheet_dic, cols_to_itter, lift):\n",
    "  \"\"\"\n",
    "  Updates the records from a given comp sheet\n",
    "\n",
    "  rec_dict: The dictionary of the current records sheets\n",
    "  clean_sheet: The sheet we want to update the records from\n",
    "  min_val: The smallest attempt in the sheet\n",
    "  max_val: The largest attempt in the sheet\n",
    "  wt_clsses: The list of weight classes we want to update the records for\n",
    "  class_sheet_dic: The dictictionary that lets us know what records sheet goes with what category\n",
    "  cols_to_itter: The list of columns we want to itterate through to find the records, it has to be in order from sn1-sn3 then cj1-cj3\n",
    "  lift: The lift we are doing the records updates for\n",
    "  \"\"\"\n",
    "  for wt_cl in wt_clsses:\n",
    "    #There is no reccord for this weightclass beccause of the change so we skip\n",
    "    if wt_cl == '98' or wt_cl == int(98):\n",
    "      continue\n",
    "    curr_sheet = clean_sheet[clean_sheet['W.C.'] == wt_cl]\n",
    "    curr_sheet = curr_sheet.sort_values(by='Lot', ascending=True) #Making sure we are in order again just in case, make sure this variable is numeric\n",
    "    #print(curr_sheet)\n",
    "    curr_sheet = curr_sheet.reset_index(drop=True) #Having the index reset will allow us to refer back to rows when we need\n",
    "    #print(curr_sheet)\n",
    "    #Starting with snatches\n",
    "    for att in range(int(min_val), int(max_val+1)): #We use integers as there are not half value attemps\n",
    "      next = False #Settin the varible to tell us we we must go to the next attemps\n",
    "      for cols in cols_to_itter:\n",
    "        ct_inv = list(curr_sheet[cols])\n",
    "        for i in range(len(ct_inv)):\n",
    "          the_try = ct_inv[i]\n",
    "          #print(the_try)\n",
    "          if the_try == att: #Note that we move past negitives which are failed attempts, or null enteries\n",
    "            #print(the_try, att)\n",
    "            #Set up for the next itteration\n",
    "            next = True\n",
    "            #Getting the needed values for the update\n",
    "            lot_num = list(curr_sheet['Lot'])[i]\n",
    "            last_name = list(curr_sheet['Last_Name'])[i]\n",
    "            first_name = list(curr_sheet['First_Name'])[i]\n",
    "            comp_date = list(curr_sheet['Comp_Date'])[i]\n",
    "            comp_date =  pd.to_datetime(comp_date,  errors=\"raise\").strftime(\"%Y-%m-%d\") #Make sure it is in the right form\n",
    "            comp_name = list(curr_sheet['Comp_Name'])[i]\n",
    "            mst_age = list(curr_sheet['Mst_Age'])[i]\n",
    "            sex = list(curr_sheet['Sex'])[i]\n",
    "            group = list(curr_sheet['Group'])[i]\n",
    "            yob = list(curr_sheet['YOB'])[i]\n",
    "            prop_cat = list(curr_sheet['Prop_cat'])[i]\n",
    "            club = list(curr_sheet['Club'])[i]\n",
    "            #Checking to see if we need to update\n",
    "            rsheet_key = group + \"_\" + sex\n",
    "            rsheet_key = re.sub(r\"\\s+\", \"\", str(rsheet_key)) #Removing just in case\n",
    "            rsheet_in_q = rec_dic[class_sheet_dic[rsheet_key]]\n",
    "            #print(rsheet_in_q)\n",
    "            rsheet_in_q = rsheet_in_q.reset_index(drop = True) #Making sure we can cleanly refer back to what we need to each time\n",
    "            wc_use = str(wt_cl) + \"kg\" #The weightclass in the sheet\n",
    "            if '+' in wc_use: #Make sure the heavyweight classes are in the proper form\n",
    "              wc_use = \"+\" + wc_use.replace(\"+\", \"\", 1)\n",
    "            #Handeling each update case\n",
    "            if group == \"MST\":\n",
    "              #For the masters sheet\n",
    "              cat_val = sex + str(int(mst_age))\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key, last_name, first_name, cat_val, wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "              #Need to update SR as well\n",
    "              rsheet_key2 = \"SR\" + \"_\" + sex\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key2, last_name, first_name, \"SR\", wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "              break\n",
    "            elif group == \"JR\":\n",
    "              #For the junior sheet\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key, last_name, first_name, group, wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "              rsheet_key2 = \"SR\" + \"_\" + sex\n",
    "              #Need to update for SR as well\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key2, last_name, first_name, \"SR\", wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "              break\n",
    "            elif group == \"YTH\":\n",
    "              #For the youth\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key, last_name, first_name, group, wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "              #Note that we will need to update for youth athletes breaking JR and SR records\n",
    "              break\n",
    "            elif group == \"SR\":\n",
    "              #For the senior\n",
    "              rec_dic = update_sequence(rec_dic, clean_sheet, class_sheet_dic, rsheet_key, last_name, first_name, group, wc_use, lift, club, the_try, comp_name, comp_date)\n",
    "            break\n",
    "          else: #Business as usuall if we do not hit an attempt\n",
    "            next = False\n",
    "        #Stopping all innter itterations if we have found a record for this attempt\n",
    "          if next == True:\n",
    "            break\n",
    "        if next == True:\n",
    "          break\n",
    "  #Return the updated record dictionary\n",
    "  return rec_dic\n",
    "\n",
    "def rec_sheet_update(rec_dic, upd_dic, class_sheet_dic):\n",
    "  \"\"\"\n",
    "  This function updates the record sheets\n",
    "\n",
    "  rec_dic: The dictionary of the current records sheets\n",
    "  upd_dic: The dictionary of the new competitions into the sheet\n",
    "  class_sheet_dic: The dictictionary that lets us know what records sheet goes with what category\n",
    "  quota: The maximum amount of updates we can make to a google sheet in one operaion\n",
    "  \"\"\"\n",
    "  #Gets the needed information to order the updates of the sheets\n",
    "  upd_keys = list(upd_dic.keys())\n",
    "  upd_split = list_string_split(upd_keys, '_', 1)\n",
    "  dates = list_unpacker(upd_split, 0)\n",
    "  dates_sorted = sorted(dates, key=lambda d: datetime.strptime(d, \"%Y-%m-%d\"))\n",
    "  orderd_keys = date_key_sort(upd_keys, dates_sorted)\n",
    "  sn_cols_to_test = ['Snatch_1', 'Snatch_2', 'Snatch_3']\n",
    "  cj_cols_to_test = ['Clean&Jerk_1', 'Clean&Jerk_2', 'Clean&Jerk_3']\n",
    "  tot_cols_to_test = ['Total']\n",
    "  cols_to_test = sn_cols_to_test + cj_cols_to_test + tot_cols_to_test\n",
    "  #print(orderd_keys)\n",
    "  #Updating the records\n",
    "  for comp in orderd_keys:\n",
    "    comp_results = upd_dic[comp]\n",
    "    comp_results[\"Lot\"] = comp_results[\"Lot\"].astype(int) #Makes sure we are in the right form\n",
    "    #Doing some basic mods before we start finding the records\n",
    "    comp_resrec = comp_results[['Lot', 'Last_Name', 'First_Name', 'Group', 'Club','Snatch_1', 'Snatch_2', 'Snatch_3', 'Snatch_max', 'Clean&Jerk_1',\n",
    "                                'Clean&Jerk_2', 'Clean&Jerk_3', 'Clean&Jerk_max', 'Total', 'YOB', 'Mst_Age', 'Sex', 'W.C.', 'Prop_cat',\n",
    "                                'Comp_Date', 'Comp_Name']]\n",
    "    cc_comp_res = proper_null_convert(comp_resrec, cols_to_test)\n",
    "    #Mens updates\n",
    "    #Getting the dataframe in order\n",
    "    mens_res = cc_comp_res[cc_comp_res['Sex'] == 'M']\n",
    "    msort_res = (mens_res.sort_values(by='Lot', ascending=True)).reset_index(drop=True)\n",
    "    #print(msort_res)\n",
    "    m_wcl = list(msort_res['W.C.'].unique())\n",
    "    #Gettin the max and mins of each lift\n",
    "    sn_mens_min, sn_mens_max = max_min_finder(msort_res, sn_cols_to_test)\n",
    "    cj_mens_min, cj_mens_max = max_min_finder(msort_res, cj_cols_to_test)\n",
    "    to_mens_min, to_mens_max = max_min_finder(msort_res, tot_cols_to_test)\n",
    "    rec_dic = reccord_sequence(rec_dic, msort_res, sn_mens_min, sn_mens_max, m_wcl, class_sheet_dic, sn_cols_to_test, \"Snatch\")\n",
    "    rec_dic = reccord_sequence(rec_dic, msort_res, cj_mens_min, cj_mens_max, m_wcl, class_sheet_dic, cj_cols_to_test, \"Clean&Jerk\")\n",
    "    rec_dic = reccord_sequence(rec_dic, msort_res, to_mens_min, to_mens_max, m_wcl, class_sheet_dic, tot_cols_to_test, \"Total\")\n",
    "    #Womans updates\n",
    "    womens_res = cc_comp_res[cc_comp_res['Sex'] == 'W']\n",
    "    wsort_res = (womens_res.sort_values(by='Lot', ascending=True)).reset_index(drop=True)\n",
    "    w_wcl = list(wsort_res['W.C.'].unique())\n",
    "    sn_womens_min, sn_womens_max = max_min_finder(wsort_res, sn_cols_to_test)\n",
    "    cj_womens_min, cj_womens_max = max_min_finder(wsort_res, cj_cols_to_test)\n",
    "    to_womens_min, to_womens_max = max_min_finder(wsort_res, tot_cols_to_test)\n",
    "    rec_dic = reccord_sequence(rec_dic, wsort_res, sn_womens_min, sn_womens_max, w_wcl, class_sheet_dic, sn_cols_to_test, \"Snatch\")\n",
    "    rec_dic = reccord_sequence(rec_dic, wsort_res, cj_womens_min, cj_womens_max, w_wcl, class_sheet_dic, cj_cols_to_test, \"Clean&Jerk\")\n",
    "    rec_dic = reccord_sequence(rec_dic, wsort_res, to_womens_min, to_womens_max, w_wcl, class_sheet_dic, tot_cols_to_test, \"Total\")\n",
    "  return rec_dic\n",
    "\n",
    "def rec_sheet_updates(sheet_path, rec_sheet, match_dict):\n",
    "  \"\"\"\n",
    "  Updates the record sheets in the google sheet\n",
    "\n",
    "  sheet_path: The full path to the excell sheet in googled drive\n",
    "  rec_sheet: The dictionary that contains the updated record sheets\n",
    "  match_dict: The dictionary that lets us know what records sheet goes with what category\n",
    "  \"\"\"\n",
    "  #Set needed packages internally\n",
    "  from google.colab import auth\n",
    "  import google.auth\n",
    "  #Authenticate and open the sheet\n",
    "  auth.authenticate_user()\n",
    "  #Update\n",
    "  for key in list(match_dict.keys()):\n",
    "    sheet = match_dict[key]\n",
    "    print(\"Updating: \", sheet)\n",
    "    repl_sheet = rec_sheet[sheet]\n",
    "    old_sheet = pd.read_excel(sheet_path, sheet_name=sheet)\n",
    "    title_text = old_sheet.columns[0] #Get the header of the dataframe to be replaced\n",
    "    with pd.ExcelWriter(sheet_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "      repl_sheet.to_excel(writer, index=False, startrow=1, sheet_name=sheet)\n",
    "      #Get workbook and worksheet\n",
    "      workbook = writer.book\n",
    "      worksheet = writer.sheets[sheet]\n",
    "      #Place the title in the first cell (row=1, col=1)\n",
    "      worksheet.cell(row=1, column=1, value=title_text)\n",
    "      #Merge across all dataframe columns and bold\n",
    "      worksheet.merge_cells(start_row=1, start_column=1, end_row=1, end_column=len(repl_sheet.columns))\n",
    "      cell = worksheet.cell(row=1, column=1)\n",
    "      cell.font = Font(bold=True, size=16)\n",
    "      cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "      #Define a thin black border and then add the boarder to the cells\n",
    "      thin_border = Border(\n",
    "      left=Side(style=\"thin\", color=\"000000\"),\n",
    "      right=Side(style=\"thin\", color=\"000000\"),\n",
    "      top=Side(style=\"thin\", color=\"000000\"),\n",
    "      bottom=Side(style=\"thin\", color=\"000000\"))\n",
    "      for row in worksheet.iter_rows(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column):\n",
    "        for cell in row:\n",
    "          if isinstance(cell, MergedCell):\n",
    "            continue  # skip the \"phantom\" merged cells\n",
    "          cell.border = thin_border\n",
    "          ## (optional) wrap text so borders look neat with long strings\n",
    "          #cell.alignment = Alignment(wrap_text=True, vertical=\"top\")\n",
    "      #Makes the cells wider\n",
    "      for col_idx, col_cells in enumerate(worksheet.iter_cols(min_row=2, max_row=worksheet.max_row, min_col=1, max_col=worksheet.max_column), start=1):\n",
    "        max_len = 0\n",
    "        for cell in col_cells:\n",
    "          if isinstance(cell, MergedCell):\n",
    "            continue  # skip placeholder cells from merged ranges\n",
    "          if cell.value is not None:\n",
    "            max_len = max(max_len, len(str(cell.value)))\n",
    "        worksheet.column_dimensions[get_column_letter(col_idx)].width = max_len + 1\n",
    "    print(\"Updated: \", sheet)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YnazlKP_eRra",
    "outputId": "88eaffaf-ace7-4b4c-ba34-6be64959ede3"
   },
   "outputs": [],
   "source": [
    "#6) \n",
    "\n",
    "#Run all update operations and updates\n",
    "#Note that you may need to change some of the functions and there inputs depending if you are using a google sheet or an excell file\n",
    "#The function that is not a base pandas or other stock uploader \"sheet_dict_creater\". It is in cell #5\n",
    "\n",
    "#Upload each file needed for the updates as a dictionary, and get into a form that we can run the updates on\n",
    "print(\"Uploading Required Sheets\")\n",
    "\n",
    "#Rankings sheets\n",
    "rank_sheets = [\"2025-26 ALL FEMALE\", \"2025-26 ALL MALE\"]\n",
    "rank_dict_in = sheet_dict_creater(rank_sheet_ID, rank_sheets, \"gsheet\", True)\n",
    "#print(rank_dict_in)\n",
    "rank_to_upd = rank_sheet_mod1(rank_dict_in)\n",
    "#print(rank_to_upd)\n",
    "\n",
    "#Records sheets (Note that the whole name is not avalilible for each tab here)\n",
    "#xls = pd.ExcelFile(rec_sheet_path) #To get the actual sheet names\n",
    "#print(xls.sheet_names)\n",
    "rec_sheets = ['Womens Sr (2025+ weight classes', 'Mens Sr (2025+ weight classes)', 'Womans Jr (2025+ weight classes', 'Mens Jr (2025+ weight classes)', 'Womens Yth (2025+ weight classe', 'Mens Yth (2025+ weight classes)', 'Womens Masters (2025+ weight cl', 'Mens Masters (2025+ weight clas','Previous Records 2025+'] #Names that are stored in the sheet\n",
    "#rec_sheets = ['Womens Sr (2025+ weight classes)', 'Mens Sr (2025+ weight classes)', 'Womans Jr (2025+ weight classes)',  'Mens Jr (2025+ weight classes)', 'Womens Yth (2025+ weight classes)', 'Mens Yth (2025+ weight classes)', 'Womens Masters (2025+ weight classes)', 'Mens Masters (2025+ weight classes)','Previous Records 2025+'] #Full names\n",
    "rec_dict_in = sheet_dict_creater(rec_sheet_path, rec_sheets, \"xlsx\", False)\n",
    "#print(rec_dict_in)\n",
    "rec_to_upd = rec_sheet_mod1(rec_dict_in)\n",
    "\n",
    "#Update sheets\n",
    "upd_sheets, non_matched = upd_sheed_upload(res_to_add_path)\n",
    "#print(upd_sheets) #-Remember that there will be different ways to see missed attemps ((), -, ...)\n",
    "#print(non_matched) - Note that we will need to reorganize the sheet to see who hit what when. This is done by the lot number\n",
    "unrec_frame(non_matched) #Making sure that we have every frame reccognized\n",
    "cc_upd_dict = column_samer(upd_sheets)\n",
    "#print(cc_upd_dict)\n",
    "\n",
    "#Classification sheet\n",
    "curr_clsheetname = \"Classification_2025-2026\"\n",
    "male_classheet, female_classheet = classification_setup(class_sheet_path, curr_clsheetname)\n",
    "#print(male_classheet)\n",
    "#print(female_classheet)\n",
    "\n",
    "#Sinclair constant sheet\n",
    "sinc_sheetname = \"Sinclair_Constants\"\n",
    "sinc_sheet = pd.read_excel(sinc_sheet_path, sheet_name=sinc_sheetname)\n",
    "#print(sinc_sheet)\n",
    "\n",
    "#Q-Points masters age factors upload\n",
    "Qf_sheetname = \"Q_Masters_Age_Factors\"\n",
    "Q_agef_sheet = pd.read_excel(Q_agef_sheet, sheet_name=Qf_sheetname)\n",
    "#print(Q_agef_sheet)\n",
    "\n",
    "#Adding needed information to the update dictionary so we can update the records and rankings\n",
    "print(\"Organizing uploaded sheets\")\n",
    "cc_upd_dict_2 = upd_dict_infoadd(cc_upd_dict, sinc_sheet, male_classheet, female_classheet)\n",
    "#print(cc_upd_dict_2)\n",
    "\n",
    "#Updaing the internal ranking dataframe\n",
    "print(\"Updating rankings sheet\")\n",
    "rank_dict_keys = {'Male_Ranks':'2025-26 ALL MALE', 'Female_Ranks':'2025-26 ALL FEMALE', 'Other_ranks':np.nan} #Update the values of the dictionary as the sheet changes, dont changes the keys\n",
    "rank_column = \"WC_Sinclair\" #Change this if you want to do the ranking by a different standard\n",
    "rank_to_upd = rankings_updator(rank_to_upd, cc_upd_dict_2, rank_column, \"Sex\", rank_dict_keys, '2025-06-01', '2026-05-31')\n",
    "#print(rank_to_upd)\n",
    "\n",
    "#Updating the internal records sheets\n",
    "print(\"Updating records sheet\")\n",
    "cat_clases = ['SR_W', 'SR_M', 'JR_W', 'JR_M', 'YTH_W', 'YTH_M', 'MST_W', 'MST_M', 'HIST']\n",
    "class_sheet_dict = class_cat_dbuild(rec_sheets, cat_clases)\n",
    "#print(class_sheet_dict)\n",
    "new_rec_sheets = rec_sheet_update(rec_to_upd, cc_upd_dict_2, class_sheet_dict)\n",
    "#print(new_rec_sheets)\n",
    "\n",
    "#Functions to update the ranking sheet\n",
    "#Note that this cell takes a few minutes to run due to the google API request quotas\n",
    "if onl_upd_rank == True:\n",
    "  #Update the male sheet\n",
    "  print(\"Updating rankings sheets\")\n",
    "  rank_sheet_update(rank_sheet_ID, rank_dict_keys[\"Male_Ranks\"], rank_to_upd[rank_dict_keys[\"Male_Ranks\"]], 3, 59)\n",
    "  #Update the female sheet\n",
    "  rank_sheet_update(rank_sheet_ID, rank_dict_keys[\"Female_Ranks\"], rank_to_upd[rank_dict_keys[\"Female_Ranks\"]], 3, 59)\n",
    "\n",
    "#Updating the record sheet\n",
    "if onl_upd_recs == True:\n",
    "  print(\"Updating records sheets\")\n",
    "  rec_sheet_updates(rec_sheet_path, new_rec_sheets, class_sheet_dict)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
